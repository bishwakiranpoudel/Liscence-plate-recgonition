{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDlJKYMDTyV5",
        "outputId": "bae1f496-0cd3-4fe8-8be7-945587b262ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/inspiring-lab/nepali-number-plate-characters-dataset\n",
            "License(s): Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
            "Downloading nepali-number-plate-characters-dataset.zip to /content\n",
            " 89% 28.0M/31.6M [00:03<00:00, 13.9MB/s]\n",
            "100% 31.6M/31.6M [00:03<00:00, 10.5MB/s]\n",
            "Dataset downloaded and extracted successfully.\n"
          ]
        }
      ],
      "source": [
        "# prompt: get this datasethttps://www.kaggle.com/datasets/inspiring-lab/nepali-number-plate-characters-dataset/data\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "\n",
        "# Create a .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d inspiring-lab/nepali-number-plate-characters-dataset\n",
        "\n",
        "# Extract the dataset\n",
        "with ZipFile('nepali-number-plate-characters-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('nepali_number_plate_dataset')\n",
        "\n",
        "# Optionally remove the zip file after extraction\n",
        "!rm nepali-number-plate-characters-dataset.zip\n",
        "\n",
        "print(\"Dataset downloaded and extracted successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "HRgeZ69rb7um"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharacterDataset(Dataset):\n",
        "  def __init__(self, root_dir, transform=None):\n",
        "      self.root_dir = root_dir\n",
        "      self.transform = transform\n",
        "      self.classes = os.listdir(root_dir)\n",
        "      self.image_paths = []\n",
        "      self.labels = []\n",
        "\n",
        "      for label, class_name in enumerate(self.classes):\n",
        "          class_dir = os.path.join(root_dir, class_name)\n",
        "          for image_name in os.listdir(class_dir):\n",
        "              image_path = os.path.join(class_dir, image_name)\n",
        "              self.image_paths.append(image_path)\n",
        "              self.labels.append(label)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.image_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      image_path = self.image_paths[idx]\n",
        "      image = Image.open(image_path).convert('RGB')\n",
        "      label = self.labels[idx]\n",
        "\n",
        "      if self.transform:\n",
        "          image = self.transform(image)\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "wDubMiWUcKEO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "UAlq2IpNeqyN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/character_ocr\"\n",
        "dataset = CharacterDataset(root_dir=data_dir, transform=transform)"
      ],
      "metadata": {
        "id": "3ZYNw_uHezXX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices, test_indices = train_test_split(\n",
        "    list(range(len(dataset))),\n",
        "    test_size = 0.2,\n",
        "    stratify = [dataset[i][1] for i in range(len(dataset))],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create train and test subsets\n",
        "train_subset = Subset(dataset, train_indices)\n",
        "test_subset = Subset(dataset, test_indices)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "F7gq_jCkfQsR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_pS_phogKFb",
        "outputId": "d1524fff-bc7e-442d-e8c1-bf682f408550"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "model = model.to(device)\n",
        "optimizer  = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txniTWoZgTA_",
        "outputId": "ace53264-94b0-4d37-cb0b-c770c1070777"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  all_preds_train = []\n",
        "  all_labels_train = []\n",
        "\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    all_preds_train.extend(preds.cpu().numpy())\n",
        "    all_labels_train.extend(labels.cpu().numpy())\n",
        "\n",
        "  epoch_loss = running_loss / len(train_loader)\n",
        "  print(f'Epoch {epoch+1}')\n",
        "\n",
        "  model.eval()\n",
        "  val_loss=0.0\n",
        "  all_preds_val = []\n",
        "  all_labels_val = []\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      all_preds_val.extend(preds.cpu().numpy())\n",
        "      all_labels_val.extend(labels.cpu().numpy())\n",
        "  val_loss /= len(test_loader)\n",
        "  precision_val = precision_score(all_labels_val, all_preds_val, average='weighted')\n",
        "  recall_val = recall_score(all_labels_val, all_preds_val, average='weighted')\n",
        "  f1_val = f1_score(all_labels_val, all_preds_val, average='weighted')\n",
        "  print(f'Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Precision: {precision_val:.4f}, Recall: {recall_val:.4f}, F1 Score: {f1_val:.4f}')\n",
        "\n",
        "  print(f'Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQpOgh7AgtA2",
        "outputId": "d30d5f57-058f-4a15-cdcf-aabcef822df9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Train Loss: 0.3035, Val Loss: 0.1626, Precision: 0.9602, Recall: 0.9555, F1 Score: 0.9555\n",
            "Training Loss: 0.3035, Validation Loss: 0.1626\n",
            "Epoch 2\n",
            "Train Loss: 0.0818, Val Loss: 0.0923, Precision: 0.9745, Recall: 0.9725, F1 Score: 0.9728\n",
            "Training Loss: 0.0818, Validation Loss: 0.0923\n",
            "Epoch 3\n",
            "Train Loss: 0.0629, Val Loss: 0.1225, Precision: 0.9654, Recall: 0.9629, F1 Score: 0.9632\n",
            "Training Loss: 0.0629, Validation Loss: 0.1225\n",
            "Epoch 4\n",
            "Train Loss: 0.0509, Val Loss: 0.0721, Precision: 0.9801, Recall: 0.9798, F1 Score: 0.9798\n",
            "Training Loss: 0.0509, Validation Loss: 0.0721\n",
            "Epoch 5\n",
            "Train Loss: 0.0464, Val Loss: 0.1327, Precision: 0.9674, Recall: 0.9633, F1 Score: 0.9629\n",
            "Training Loss: 0.0464, Validation Loss: 0.1327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model.state_dict(), 'ocr.pth')\n",
        "from google.colab import files\n",
        "files.download('ocr.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zN92cfNHleZp",
        "outputId": "a38da362-f0b8-49cb-b49a-44b61f8fee43"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fd980863-23c1-436e-b966-23540121637a\", \"ocr.pth\", 44847686)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}